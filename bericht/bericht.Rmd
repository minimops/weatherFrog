---
title: |
  ![](lmu.jpg)
  Clusteranalyse von Wetterdaten zur Identifikation von Wetterlagetypen  
subtitle: |
  | Bericht zum Statistischen Praktikum im WS 2020/21
  |
  |
  | Betreuer: Prof. Dr. Helmut Küchenhoff
  | Projektpartner: Maximilian Weigert und Magdalena Mittermeier 
  |
  |
author: "Katja Gutmair, Noah Hurmer, Stella Akouete und Anne Gritto"
date: "01. März 2021"
output: 
  pdf_document:
    highlight: tango
    number_sections: true
    fig_width: 7
    fig_height: 3
    fig_caption: true
header-includes:
  - \usepackage{setspace}\onehalfspacing
  - \usepackage{float}
  - \setlength{\parskip}{0em}
  - \usepackage[font={small,it}, labelfont={bf}]{caption}
bibliography: references.bib
abstract: |
  to be written.
geometry: margin=2.5cm
fontsize: 11pt
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(checkmate)
library(knitr)
library(cluster)
library(kableExtra)
longrun = FALSE # set to TRUE to rerun all code
```



\newpage

\newcounter{savepage}
\pagenumbering{Roman}

\setcounter{tocdepth}{4}
\renewcommand{\contentsname}{Inhaltsverzeichnis}
\tableofcontents

\renewcommand{\listtablename}{Tabellenverzeichnis}
\listoftables

\newpage

\renewcommand{\listfigurename}{Abbildungsverzeichnis}
\listoffigures

\section*{Abkürzungen}


```{r Abkürzungen, echo=FALSE}
data.table(
  Ausdruck = c("Großwetterlage", "Clustering Large Applications", "Luftdruck in Pascal auf Meeresspiegelhöhe",
           "Geopotential auf 500 hPa in $m^2/s^2$", "Kovarianzmatrix", "Principle Component Analysis", "Partitioning Around Medoids",
           "Density-Based Spatial Clustering of Applications with Noise", "Ludwig-Maximilians-Universität"),
  Kurzform = c("GWL", "CLARA", "Mslp", "Geopotential", "$\\mathcal{C}$", "PCA", "PAM", "DBSCAN", "LMU")) %>%
  arrange(Ausdruck) %>%
  kable(booktabs = TRUE, format =  "latex", escape = FALSE) %>%
  kable_styling(latex_options = c("repeat_header", "striped"), full_width = TRUE)
```

\newpage

\setcounter{savepage}{\arabic{page}}

\pagenumbering{arabic} 

# Einleitung
Der Klimawandel bringt viele Veränderungen mit sich. Magdalena Mittermeier vom Department für Geografie und Maximilian Weigert vom Statistischen Institut der LMU untersuchen, wie sich auch das Auftreten verschiedener Großwetterlagen (GWL) unter dem Einfluss des Klimawandels verändert. 

Im Rahmen des Statistischen Praktikums unterstützen wir dieses Projekt, indem wir beobachtete Wetterdaten auf täglicher Basis in Cluster einteilen.

## Großwetterlagen
Es gibt mehrere Systeme, die Wettertypen klassifizieren. Die uns zur Verfügung gestellte Einteilung in Großwetterlagen beruht auf dem Katalog nach Hess und Brezowsky, der im Jahr 1952 veröffentlicht wurde. Es wurden 29 Großwetterlagen über Europa und dem Atlantik definiert. Zudem gibt es die Kategorie Unbestimmt (U), die angegeben wurde, wenn sich ein Tag keiner GWL zuordnen ließ (siehe @pik119). Die jeweiligen Tage lassen sich anhand von mehreren Variablen einteilen (TODO nachschauen wonach die eingeteilt werden!) 


## Daten
Seit 1900 wird viermal täglich an 160 Standorten das Geopotential auf 500 hPa in $m^2/s^2$ und der Luftdruck (Mslp) in Pascal auf Meeresspiegelhöhe erhoben. Diese Variablen sind Teil des Reanalyse-Datensatzes ERA-20C, der für die Analysen zur Verfügungung steht. Außerdem ist uns die GWL für jeden Tag im Zeitraum von 1900 bis 2010 bekannt. Im Rahmen des Statistischen Praktikums wird mit dem Reanalyse-Datensatz geclustert.

 
## Cluster
## Distanzmetriken


# Methodik
## Clustern mit den Originaldaten


### Filter Ansatz

-erklaerung gwl beschreibung
Beim genaueren Blick in die Beschreibungen einzelner GWL ist zu erkennen, dass diese häufig duch Position oder Formation bestimmter Gebiete mit erkennbar höheren oder tieferen Messwerten definiert sind. \textcolor{red}{Beispiele?}
Beispielsweise wird die GWL Trog Westeuropa (TRW) definiert durch ein sich vertikal erstreckendes Tiefdruckgebiet von Skandinavien bis zur Iberischen Halbinsel, flankiert von Hochdruckgebieten über dem Atlantik und Westrussland. Hingegen die GWL Hoch Britische Inseln (HB) ist, wie der Name bereits vermuten lässt, beschrieben durch ein Hochdruckgebiet über dem Vereinigten Königreich und Irland, umgeben von mehreren Tiefdruckgebieten (@sklima). Ähnlich ist dies bei allen weiteren Großwetterlagen zu beobachten.
-erklärung motivation
Demnach lässt sich vermuten, dass die GWL sich anhand der Position und Form der an dem Tag respektiven Hoch- und Tief(druck)gebiete sinnvoll gruppieren \textcolor{red}{ließen}. 
-erklärung prinzip
Diesen Grundgedanken verfolgend, sind die Tage optimalerweise in interessierende Gebiete zu unterteilen und anhand dieser miteinander zu vergleichen. "Interessierende Gebiete" wurden hierbei vorerst angenommen als die Gebiete um die täglich gemessenen Extrema. Folglich also einem Gebiet höherer Messwerte um den am Tag maximal gemessenen Wert und einem Gebiet tieferer Messwerte um den minimalen Messwert. Dabei ist zu beachten, dass diese Gebiete nicht zu groß werden aber auch nicht nur aus einzelnen wenigen Punkten bestehen. Außerdem sollte ihre Form, unabhängig der Messwerte, nicht zum Beispiel immer einen Kreis darstellen. Beides führte später zu Problemen bei dem Vergleich zwischen den Tagen. Alle Standorte nicht in den interessanten Gebieten sollten beim Vergleich der Tage natürlich nicht mit einbezogen werden, demnach bei der Gebietseinteilung als Rauschen bezeichnet werden. Um diese Gebietseinteilung eines Tages durchzuführen soll also ein metrischer Messwert eines bestimmten Standortes mit einer Gebietszugehörigkeit erstzt werden. Die Messinformationen des Tagen sollen also "gefiltert" werden. Da sonst bestimmte Hyperparameter oder Grenzwerte fest angegeben werden müssten, lässt sich dies durch ein seperates Clusterverfahren über die 160 Standorte pro Tag erreichen. Mit der Idee anhand beider Parameter-Messwerte (Mslp und Geopotential) "Gebiete-Muster" zu erkennen und, da durch experimentieren herausgefunden wurde, dass die beiden Parameter vereinigt keine besonders sauberen Muster zu erkennen ließen, wird jeder Tag zwei mal auf diese Weise geclustered; jeweils pro Parameter ein Mal. Die Feature-Variablen dieses Clusterverfahrens sind demnach Longitude, Latitude und der Parametermesswert. 
-erklärung verusche mit DBSCAN oder fuzzy
Um der Anforderung der nicht uniformen Gebiete gerecht zu werden, erscheint ein dichtebasiertes Clusterverfahren von Vorteil. Ein implementiertes Verfahren, das auch die Möglichkeit des Rauschens beinhaltet, ist DBSCAN (Density-Based Spatial Clustering of Applications with Noise). \textcolor{red}{DBSCAN erklären?}
DBSCAN benötigt keine Angabe der Clusteranzahl, sonder nur der Hyperparameter *minPoints* (minimal Anzahl an Punkte pro Cluster) und *eps* (Nachbarschaftsparameter). Hier lässt sich erhoffen, dass eventuell auch mehr als nur die zwei Gebiete um die Extrema erkannt werden. Allerdings musste schnell erkannt werden, dass der Algorythmus mit diesen Daten sich sehr sensitiv gegenüber den Hyperparametern präsentiert, selbst wenn der Nachbarschaftsparameter pro Tag anhand dem Wert der grössten \textcolor{red}{Curviture eines kNN-Plots} spezifisch berechnet wird. \textcolor{red}{zeigen} Dies führt dazu, dass sehr viele Tage nur zu Noise, einem einzigen Cluster oder zu riesigen Clustern gefiltert werden, was natürlich widerrum nicht erwünscht ist, da die Vergleichbarkeit der Tage im Nachhinein damit nahezu unmöglich wird. \textcolor{red}{beispiel ergebnisse} Ein Bestimmen der Startpunkte und somit ein Festsetzen der Cluster-Orte ist - zumindest in vorhandenen Implementationen dieses Algorythmus' - nicht möglich.
Ein weiterer vielversprechender Ansatz ist das Fuzzy-Clustering \textcolor{red}{Fuzzy erklären?}, da hier Startpunkte angegeben werden können und anhand der Clusterzugehörigkeitswahrscheinlichkeit jeder Beobachtung, bestimmte Beobachttungen mithilfe eines Schwellenwertes im Nachhinein zu Rauschen verwandelt werden können. 
Neben dem, dass Fuzzy üblicherweise rechentechnisch sehr teuer implementiert ist, kommt hinzu, dass dieses Verfahren natürlich auf ein Mittelpunkt pro Cluster beruht und die Distanz dazu anhand eines gegebenen Distanzmaß' bestimmt wird. Nachdem die Koordinaten als Variablen aufgenommen werden, führt dies zu Clustern gleicher Form und verletzt somit die Anforderung die Form eines Gebietes möglichst getreu darzustellen. \textcolor{red}{beispiel ergebnisse}

-vorstellen custom cluster algo
-vorstellen rand.index und custom distance




## Clustern mit extrahierten Daten
Ein weiterer Ansatz ist, dass Informationen aus dem Reanalyse Datensatz extrahiert werden und diese dann Variablen eines neuen Datensatzes werden. Diese Idee knüpft an den des vorher beschriebenen Ansatz des Filterns an. Auch hier ist die Lage von Extremwerten von Interesse. Zwar wird hier die Form der jeweiligen Tief- und Hochdruckgebiete vernachlässigt, aber es lassen sich weitere interessante Informationen mit hinzunehmen. 

Dabei versteht man unter interessanten Informationen unter anderem die Verteilung der Parameter Luftdruck und Geopotential sowie das Einbeziehen der räumlichen Ebene. Das bedeutet, der neue Datensatz beinhaltet zwei Kategorien, die Verteilung der Parameter, die bestimmte Messwerte pro Tag enthält und die räumliche Ebene, die diese dann örtlich einordnet.

Wir erhoffen uns von dieser Methodik, dass die Dimensionen weiter reduziert werden können und dass wichtige Größen spezifisch gewichtet werden können.

### Extrahieren der Variablen
Die Ausgangslage beim Extrahieren der Variablen ist dabei größtenteils der Datensatz mit 320 Dimensionen, also der, bei dem die vier Messzeitpunkte für jeden Tag gemittelt wurden. Davon extrahieren wir verschiedene Größen, die jeweils eine für uns interessante Variable über alle Standorte zusammengefasst verkörpert, wie zum Beispiel der Mittelwert des Luftdrucks über alle Standorte pro Tag. Dieser ist damit unabhängig von den Standorten und gehört zu der Kategorie "Verteilung der Parameter" am Tag. Weitere Variablen dieser Kategorie sind das Minimum und Maximum, der Median, die 0.25- und 0.75-Quantile, die Intensität und die Veränderung über den Tag jeweils für beide Parameter Luftdruck und Geopotential. 

Für das Minimum, Maximum, Median, Mittelwert und die beiden Quartile wird je ein Tag mit den 160 Standorten betrachtet, wovon diese Variablen für den Luftdruck sowie für das Geopotential extrahiert werden. 

Die Intensität wird in "Intensität Hoch" und "Intensität Tief" aufgeteilt und ist die Anzahl der Messwerte am Tag, die unter bzw. über dem 0.25- bzw. 0.75-Quantil, über alle Tage zusammen betrachtet, liegen. Sind beispielsweise an einem Tag 10 Messwerte des Geopotentials unterhalb dem 0.25-Quantil über alle Tage betrachtet, so ist die Variable "Intensität Tief Geopotential" für diesen Tag 10. Die Intention dahinter ist, dadurch zum einen, die Größe von Hoch- und Tiefdruckgebiete am Tag zu bestimmen. Hochdruckgebiete sind hier einfachhalber durch hohen Luftdruck und hohes Geopotential definiert, wobei diese Parameter getrennt voneinander betrachtet werden und analog für ein Tiefdruckgebiet. 
\textcolor{red}{evtl bezug auf internetseite mit def hoch und tiefdruckgebbiet} Das bedeutet, insgesamt gibt es 4 Variablen, die die Intensität beschreiben - Intensität Hoch und Intensität Tief je für Mslp und Geopotential. Dadurch lassen sich die Tief- und Hochdruckgebiete am Tag miteinander vergleichen. Zum anderen kann die Größe und Intensität der Gebiete über alle Tage verglichen werden, da sie in Bezug auf die Quartile über alle Tage gebildet werden. So kann es zum Beispiel sein, dass an einem Tag die Intensität des Luftdrucks für ein Hochdruckgebiet 0 ist, da an diesem Tag generell niedrige Mslp Werte beobachtet wurden. 

In Abschnitt \textcolor{red}{wahrscheinlich 1...} wurde bereits beschrieben, dass der Mittelwert über vier Messzeitpunkte pro Tag gebildet wurde. Da dies mit einem Informationsverlust einhergeht, wird die Variable "Veränderung über den Tag" eingeführt. Sie ist definiert als die summierten, absoluten Differenzen des maximalen und minimalen Messwertes für jeden Standort am Tag. Diese Variable wird folglich mit Hilfe des Originaldatensatzes, ohne Informationsverlust, für beide Parameter Mslp und Luftdruck extrahiert. 
Siehe zusammengefasst alle Extrahierten Variablen in Tabelle \ref{tab:state1}

```{r Variablen, echo=FALSE, fig.cap="\\label{tab:state1}Extrahierte Variablen für je Luftdruck und Geopotential. Each row represents a list element"}
data.table(
  Variable = c("Minimum", "Maximum", "Mittelwert", "Median", "Quartile", "Intensität Hoch", "Intensität Tief", 
               "Veränderung über den Tag", "Spalte Minimum", "Zeile Minimum", "Spalte Maximum", "Zeile Maximum",
               "Distanz zwischen Extrema", "Distanz der beiden Minima", "Distanz der beiden Maxima", 
               "Mittelwerte in den Quadranten"),
  Definition = c("Minimaler Wert pro Tag", "Maximaler Wert pro Tag", "Mittelwert pro Tag", "Median pro Tag", 
                 "Quartile pro Tag", 
                 "Anzahl der Messpunkte am Tag, die über alle Daten über dem 0.75-Quantil liegen", 
                 "Anzahl der Messpunkte am Tag, die über alle Daten unter dem 0.25-Quantil liegen", 
                 "Summierte Differenzen von vier Messzeitpunkten am Tag für alle Standorte",
                 "Spalte x, in dem sich Minimum befindet; x = 1, 2, 3",
                 "Zeile y, in dem sich Minimum befindet; y = 1, 2, 3",
                 "Spalte x, in dem sich Maximum befindet; x = 1, 2, 3",
                 "Spalte y, in dem sich Maximum befindet; y = 1, 2, 3",
                 "Euklidische Distanz zwischen Minimum und Maximum",
                 "Euklidische Distanz vom Minimum Geopotential zu Minimum Mslp",
                 "Euklidische Distanz vom Maximum Geopotential zu Minimum Mslp",
                 "Mittelwerte in jeweils 9 Quadranten")) %>%
  kable(booktabs = TRUE, format =  "latex", escape = FALSE, label = "state1", caption = "Extrahierte Variablen für je Luftdruck und Geopotential") %>%
  kable_styling(latex_options = "striped", full_width = TRUE)
```
### Entscheidung des Clusterverfahrens
## Analyse der Clusterergebnisse
# Schluss


\section{References}