---
title: |
  ![](lmu.jpg)
  Clusteranalyse von Wetterdaten zur Identifikation von Wetterlagetypen  
subtitle: |
  | Bericht zum Statistischen Praktikum im WS 2020/21
  |
  |
  | Betreuer: Prof. Dr. Helmut Küchenhoff
  | Projektpartner: Maximilian Weigert und Magdalena Mittermeier 
  |
  |
author: "Katja Gutmair, Noah Hurmer, Stella Akouete und Anne Gritto"
date: "01. März 2021"
output: 
  pdf_document:
    highlight: tango
    number_sections: true
    fig_width: 7
    fig_height: 3
    fig_caption: true
header-includes:
  - \usepackage{setspace}\onehalfspacing
  - \usepackage{float}
  - \setlength{\parskip}{0em}
  - \usepackage[font={small,it}, labelfont={bf}]{caption}
  - \usepackage[linesnumbered,lined,boxed,commentsnumbered]{algorithm2e} 
bibliography: references.bib
abstract: |
  to be written.
geometry: margin=2.5cm
fontsize: 11pt
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(checkmate)
library(knitr)
library(cluster)
library(kableExtra)
longrun = FALSE # set to TRUE to rerun all code
```




\newpage

\newcounter{savepage}
\pagenumbering{Roman}

\setcounter{tocdepth}{4}
\tableofcontents

\listoftables

\newpage

\listoffigures

\section*{List of abbreviations}


```{r Abkürzungen, echo=FALSE}
data.table(
  Ausdruck = c("Großwetterlage", "Clustering Large Applications", "Luftdruck in Pascal auf Meeresspiegelhöhe",
           "Geopotential auf 500 hPa in $m^2/s^2$", "Kovarianzmatrix", "Principle Component Analysis", "Partitioning Around Medoids",
           "Density-Based Spatial Clustering of Applications with Noise", "Ludwig-Maximilians-Universität", "Spatial Clustering around Points of Interest"),
  Abkuerzung = c("GWL", "CLARA", "Mslp", "Geopotential", "$\\mathcal{C}$", "PCA", "PAM", "DBSCAN", "LMU", "SCAPOI")) %>%
  arrange(Ausdruck) %>%
  kable(booktabs = TRUE, format =  "latex", escape = FALSE) %>%
  kable_styling(latex_options = c("repeat_header", "striped"), full_width = TRUE)
```

\newpage

\setcounter{savepage}{\arabic{page}}

\pagenumbering{arabic} 

# Einleitung
Der Klimawandel bringt viele Veränderungen mit sich. Magdalena Mittermeier vom Department für Geografie und Maximilian Weigert vom Statistischen Institut der LMU untersuchen, wie sich auch das Auftreten verschiedener Großwetterlagen (GWL) unter dem Einfluss des Klimawandels verändert. 

Im Rahmen des Statistischen Praktikums unterstützen wir dieses Projekt, indem wir beobachtete Wetterdaten auf täglicher Basis in Cluster einteilen.

## Großwetterlagen
Es gibt mehrere Systeme, die Wettertypen klassifizieren. Die uns zur Verfügung gestellte Einteilung in Großwetterlagen beruht auf dem Katalog nach Hess und Brezowsky, der im Jahr 1952 veröffentlicht wurde. Es wurden 29 Großwetterlagen über Europa und dem Atlantik definiert. Zudem gibt es die Kategorie Unbestimmt (U), die angegeben wurde, wenn sich ein Tag keiner GWL zuordnen ließ (siehe @pik119). Die jeweiligen Tage lassen sich anhand von mehreren Variablen einteilen (TODO nachschauen wonach die eingeteilt werden!) 


## Daten
Seit 1900 wird viermal täglich an 160 Standorten das Geopotential auf 500 hPa in $m^2/s^2$ und der Luftdruck (Mslp) in Pascal auf Meeresspiegelhöhe erhoben. Diese Variablen sind Teil des Reanalyse-Datensatzes ERA-20C, der für die Analysen zur Verfügungung steht. Außerdem ist uns die GWL für jeden Tag im Zeitraum von 1900 bis 2010 bekannt. Im Rahmen des Statistischen Praktikums wird mit dem Reanalyse-Datensatz geclustert.

 
## Cluster
## Distanzmetriken


# Methodik
## Clustern mit den Originaldaten


### Filter Ansatz

#### Motivation

  Beim genaueren Blick in die Beschreibungen einzelner GWL ist zu erkennen, dass diese häufig duch Position oder Formation bestimmter Gebiete mit erkennbar höheren oder tieferen Messwerten definiert sind. \textcolor{red}{Beispiele?}

  Beispielsweise wird die GWL Trog Westeuropa (TRW) definiert durch ein sich vertikal erstreckendes Tiefdruckgebiet von Skandinavien bis zur Iberischen Halbinsel, flankiert von Hochdruckgebieten über dem Atlantik und Westrussland. Hingegen die GWL Hoch Britische Inseln (HB) ist, wie der Name bereits vermuten lässt, beschrieben durch ein Hochdruckgebiet über dem Vereinigten Königreich und Irland, umgeben von mehreren Tiefdruckgebieten @sklima. Ähnlich ist dies bei allen weiteren Großwetterlagen zu beobachten.
  
  Demnach lässt sich vermuten, dass die GWL sich anhand der Position und Form der an dem Tag respektiven Hoch- und Tief(druck)gebiete sinnvoll gruppieren \textcolor{red}{ließen}.
  
#### Prinzip Filtern
  
  Diesen Grundgedanken verfolgend, sind die Tage optimalerweise in interessierende Gebiete zu unterteilen und anhand dieser miteinander zu vergleichen. "Interessierende Gebiete" wurden hierbei vorerst angenommen als die Gebiete um die täglich gemessenen Extrema. Folglich also einem Gebiet höherer Messwerte um den am Tag maximal gemessenen Wert und einem Gebiet tieferer Messwerte um den minimalen Messwert. Dabei ist zu beachten, dass diese Gebiete nicht zu groß werden aber auch nicht nur aus einzelnen wenigen Punkten bestehen. Außerdem sollte ihre Form, unabhängig der Messwerte, nicht zum Beispiel immer einen Kreis darstellen. Beides führte später zu Problemen bei dem Vergleich zwischen den Tagen. Alle Standorte nicht in den interessanten Gebieten sollten beim Vergleich der Tage natürlich nicht mit einbezogen werden, demnach bei der Gebietseinteilung als Rauschen bezeichnet werden. Um diese Gebietseinteilung eines Tages durchzuführen, soll also ein metrischer Messwert eines bestimmten Standortes mit einer Gebietszugehörigkeit ersetzt werden. Die Messinformationen des Tagen sollen also "gefiltert" werden. Da sonst bestimmte Hyperparameter oder Grenzwerte fest angegeben werden müssten, lässt sich dies durch ein seperates Clusterverfahren über die 160 Standorte pro Tag erreichen. Mit der Idee anhand beider Parameter-Messwerte (Mslp und Geopotential) "Gebiete-Muster" zu erkennen und, da durch experimentieren herausgefunden wurde, dass die beiden Parameter vereinigt keine besonders sauberen Muster zu erkennen ließen, wird jeder Tag zwei mal auf diese Weise geclustered; jeweils pro Parameter ein Mal. Die Feature-Variablen dieses Clusterverfahrens sind demnach Longitude, Latitude und der Parametermesswert. 
  
#### DBSCAN und Fuzzy
  
  Um der Anforderung der nicht uniformen Gebiete gerecht zu werden, erscheint ein dichtebasiertes Clusterverfahren von Vorteil. Ein implementiertes Verfahren, das auch die Möglichkeit des Rauschens beinhaltet, ist *DBSCAN* (Density-Based Spatial Clustering of Applications with Noise). \textcolor{red}{DBSCAN erklären?}
*DBSCAN* benötigt keine Angabe der Clusteranzahl, sonder nur der Hyperparameter *minPoints* (minimale Anzahl an Punkte pro Cluster) und *eps* (Nachbarschaftsparameter). Hier lässt sich erhoffen, dass eventuell auch mehr als nur die zwei Gebiete um die Extrema erkannt werden. 
  Allerdings musste schnell erkannt werden, dass der Algorythmus mit diesen Daten sich sehr sensitiv gegenüber den Hyperparametern präsentiert, selbst wenn der Nachbarschaftsparameter pro Tag anhand dem Wert der grössten \textcolor{red}{Curviture eines kNN-Plots} spezifisch berechnet wird. \textcolor{red}{zeigen} Dies führt dazu, dass sehr viele Tage nur zu Noise, einem einzigen Cluster oder zu riesigen Clustern gefiltert werden; was natürlich widerrum nicht erwünscht ist, da die Vergleichbarkeit der Tage im Nachhinein damit nahezu unmöglich wird. \textcolor{red}{beispiel ergebnisse} Ein Bestimmen der Startpunkte und somit ein Festsetzen der Cluster-Orte ist - zumindest in vorhandenen Implementationen dieses Algorythmus' - nicht möglich. Deswegen lässt sich beobachten, dass die Extrema oft nicht in einem der eingeteilten Clustern befinden, da sie sich oft stark von durchschnittlichen Messwerten abweichen. Was man mit diesem Algorythmus somit erhält, ist im besten Fall ein Herausfinden von Gebieten, dessen Messwerte durchschnittlich sind und kaum Veränderungen aufweisen. Solche Gebiete sind aber hier as nicht von besonderem Interesse vermutet.

  Ein weiterer vielversprechender Ansatz ist das *Fuzzy*-Clustering \textcolor{red}{Fuzzy erklären?}, da hier Startpunkte angegeben werden können und anhand der Clusterzugehörigkeitswahrscheinlichkeit jeder Beobachtung, bestimmte Beobachttungen mithilfe eines Schwellenwertes im Nachhinein zu Rauschen verwandelt werden können. 
  
  Neben dem, dass *Fuzzy* üblicherweise rechentechnisch sehr teuer implementiert ist, kommt hinzu, dass dieses Verfahren natürlich auf ein Mittelpunkt pro Cluster beruht und die Distanz dazu anhand eines gegebenen Distanzmaß' bestimmt wird. Nachdem die Koordinaten als Variablen aufgenommen werden, führt dies zu Clustern gleicher Form und verletzt somit die Anforderung die Form eines Gebietes möglichst getreu darzustellen. \textcolor{red}{beispiel ergebnisse}

#### SCAPOI
 
  Im Folgenden wird der benutzte Algorithmus beschrieben, der eine abgeänderte Version des *DBSCAN* darstellt. Dieser beinhaltet fixe Startpunkte und ein iterierend strenger werdendes Nachbarschaftskriterium. Er wird im folgenden immer als *SCAPOI* (Spatial Clustering around Points of Interest) benannt. 

&nbsp;

 \begin{algorithm}[H]
 \KwData{Messwerte eines Parameters der 160 Standorte am Tag}
 \KwResult{Gebietszugehörigkeitsvektor pro Tag}
 \;
 eps0 = Berechnete Distanz des Punktes der größten Krümmung in Bezug auf kNN TODO\;
 Startpunkte = Orte des gemessenen Minimums und Maximums\;
 \For{jeden Startpunkt}{
    eps = eps0\;
    beginne ein Cluster um den Startpunkt\;
    \While{Neue Punkte gefunden werden, die hinzugefügt werden}{
    Prüfe ob es Punkte gibt, die < eps von einem im Cluster existierenden Punkt entfernt sind\;
    \eIf{ein Punkt bereits einem anderen Cluster angehört}{
     Füge es dem Cluster hinzu, dessen Startpunkt es am nächsten liegt\;
     }{
     füge es dem Cluster hinzu\;
    }
    eps = reduzierter eps\;
   }
 }
 nicht zugeteilte Punkte bleiben Noise\;
 \caption{SCAPOI - Algorythmus}
\end{algorithm}
  
&nbsp;
  
  
  Die Startpunkte werden hier jeweils als die Extrema der Messpunkte gewählt. Der Nachbarschaftsparameter *eps* muss groß genug gewählt (bzw. berechnet) werden, um zu berücksichtigen, dass die Extrema im Vergleich zu anderen Messwerten stark abweichen und somit zu verhinderen, dass die Cluster gar nicht oder zu gering wachsen. Allerdings führt aber zu großer eps dann zu einem unendlichen Wachsen der Cluster, da der Abstand eines Messpunktes zu seinem Nachbar quasi fast nie größer ist, als der Abstand der Extrema zu seinen Nachbarn. Deshalb wird dieser Nachbarschaftsparameter *eps* pro iteration verkleinert.

  Im Vergleich zu *DBSCAN*, mit dem Gruppierungen von Beobachtungen gesucht werden, die einer bestimmten mindest-Dichte, sowie einer mindest-Größe gerecht werden, wird mit *SCAPOI* versucht um bestimmte definierte Beobachtungen Gruppen zu bilden, die eine gewisse Dichte aufweisen. Im Fall hier (2 Cluster um min und max respektive), erhält man nun einen Gebietszugehörigkeitsvektormit den Klassen: Noise, High und Low.
 
#### Distanzmetrik

  Um nun wieder auf Tagesebene clustern zu können, sprich mit den Tagen als Beobachtungseinheit Cluster zu bilden, benötigt man eine Metrik, mit der diese Gebietszugehörigkeitsvektoren zweier Tage mieinander verglichen werden können. Der *Rand-Index* präsentiert eine solche Möglichkeit. Dieser vergleicht jeweils, ob pro Clusterlösung Paare zweier Beobachtungen jeweils im selben cluster liegen. Obwohl dies eher gedacht ist, um Lösungen verschiedener Clusterverfahren mit denselben Beobachtungen zu vergleichen, ist der *Rand-Index* hier möglich, da die Messpunkte konstant sind.
  Allerdings ist hier irrelevant, in welchem Cluster sich das Paar jeweils befindet. Was in diesem Fall nicht erwünscht ist: Zwei Tage mit identischen Gebietsformen und -orten aber gespiegelter Zugehörigkeit sollen nicht eine Distanz von 0 zueinander aufweisen. Zu dem sind natürlich Messpunkte, die als Noise definiert wurden, nicht von Interesse und sollten demnach auch nicht mit einbezogen werden.
  Folgend wurde eine Distanzmetrik definiert, die über beide Tage alle Messpunkte, die jeweils als Noise definiert wurden, nicht betrachtet und mit den verbleibenden jeweils nur vergleicht, welche Gebietszugehörigkeit die Messpunkte jeweils aufweisen.
  \textcolor{red}{insert Formula}
  

#### Ergebnisse


## Clustern mit extrahierten Daten
### Extrahieren der Variablen
### Entscheidung des Clusterverfahrens
## Analyse der Clusterergebnisse
# Schluss


# Referenzen